{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_digits = 4\n",
    "\n",
    "base_directory = \"../results/\"\n",
    "image_results_column = \"test_accuracy\"\n",
    "time_results_column = \"mae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classification_results = [\n",
    "    # Small Image Classification\n",
    "    [\n",
    "        [\n",
    "            \"ResNet20-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet56-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet110-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ResNet20-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet56-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet110-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTS8-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTB8-cifar10-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTS8-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTB8-cifar100-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "    ],\n",
    "    # Large Image Classification\n",
    "    [\n",
    "        [\n",
    "            \"ResNet18-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet50-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet101-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ResNet18-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet50-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ResNet101-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTTiny16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTS16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTB16-oxford_flowers102-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTTiny16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTS16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "            \"ViTB16-uc_merced-idun-A100-PyTorch-ngc2312.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTTiny16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "            \"ViTS16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "            \"ViTB16-oxford_flowers102-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "        ],\n",
    "        [\n",
    "            \"ViTTiny16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "            \"ViTS16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "            \"ViTB16-uc_merced-idun-A100-PyTorch-ngc2312-pretrained.csv\",\n",
    "        ],\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_kde(data, x_label_name, save_path):\n",
    "\n",
    "    max_y = 0  # Initialize a variable to track the maximum y-axis limit across all plots\n",
    "\n",
    "    # Set the number of columns and rows for the subplots\n",
    "    ncols = 2\n",
    "    nrows = math.ceil(len(data) / ncols)  # Calculate the number of rows needed based on the data size\n",
    "\n",
    "    # Dynamically adjust figure size based on the number of rows\n",
    "    figsize = (22, 6 * nrows)\n",
    "\n",
    "    # Create subplots with the determined number of rows and columns\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    fig.tight_layout(pad=7)  # Add padding between subplots\n",
    "\n",
    "    # Ensure `ax` is always treated as a 2D array even if there's only one row or column\n",
    "    ax = np.atleast_2d(ax)\n",
    "\n",
    "    x_mid = np.zeros((nrows, ncols))  # To store the midpoints of x-axis for each subplot\n",
    "    x_range = 0  # Initialize variable to track the largest x-axis range\n",
    "\n",
    "    # Loop through the data and create a KDE plot for each item\n",
    "    for idx, title in enumerate(data):\n",
    "        column = idx % ncols  # Determine the column index for the subplot\n",
    "        row = idx // ncols    # Determine the row index for the subplot\n",
    "\n",
    "        # Plot KDEs for each model in the inner dictionary of `data[title]`\n",
    "        for model, values in data[title].items():\n",
    "            sns.kdeplot(values, ax=ax[row, column], fill=True, label=model)\n",
    "\n",
    "        ax[row, column].legend(fontsize=25)  # Add a legend with larger font size\n",
    "        ax[row, column].set_title(title, fontsize=25)  # Set the title for the subplot\n",
    "        ax[row, column].set_xlabel(x_label_name, fontsize=25)  # Label the x-axis\n",
    "        ax[row, column].set_ylabel(\"Probability Density\", fontsize=25)  # Label the y-axis\n",
    "        ax[row, column].tick_params(labelsize=20)  # Adjust tick label sizes\n",
    "\n",
    "        # Get current x-axis limits and calculate the midpoint\n",
    "        x_lim = ax[row, column].get_xlim()\n",
    "        x_mid[row, column] = (x_lim[0] + x_lim[1]) / 2  # Calculate midpoint of the x-axis range\n",
    "\n",
    "        # Update the largest x-axis range found across all plots\n",
    "        if (x_lim[1] - x_lim[0]) > x_range:\n",
    "            x_range = x_lim[1] - x_lim[0]\n",
    "\n",
    "        # Get current y-axis limits and update the global maximum y-axis limit\n",
    "        y_lim = ax[row, column].get_ylim()\n",
    "        if y_lim[1] > max_y:\n",
    "            max_y = y_lim[1]\n",
    "\n",
    "    # Set consistent x and y limits for all subplots\n",
    "    for row_idx in range(nrows):\n",
    "        for col_idx in range(ncols):\n",
    "            # Check if the current subplot corresponds to actual data\n",
    "            if row_idx * ncols + col_idx < len(data):\n",
    "                # Set x-axis limits for each plot, ensuring the range stays within [0, 100]\n",
    "                x_min = x_mid[row_idx, col_idx] - x_range / 2\n",
    "                x_max = x_mid[row_idx, col_idx] + x_range / 2\n",
    "                if x_min < 0:  # Adjust x_min and x_max if necessary to stay within bounds\n",
    "                    x_min = 0\n",
    "                    x_max = x_range\n",
    "                if x_max > 100:\n",
    "                    x_min = 100 - x_range\n",
    "                    x_max = 100\n",
    "\n",
    "                ax[row_idx, col_idx].set_xlim([x_min, x_max])\n",
    "\n",
    "                # Set the y-axis limit for each plot to ensure consistency across all plots\n",
    "                ax[row_idx, col_idx].set_ylim([0, max_y])\n",
    "\n",
    "    plt.show()  # Display the plots\n",
    "\n",
    "    # Save the figure to a file, with the file name based on the first three letters of the title\n",
    "    fig.savefig(save_path + title.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\") + \"_kde.pdf\", dpi=600, pad_inches=0.1, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary statistics so they can be saved to a CSV file\n",
    "summary_statistics = []\n",
    "\n",
    "for idx, experiment_list in enumerate(image_classification_results):\n",
    "\n",
    "    experiment_data = {}\n",
    "\n",
    "\n",
    "    for experiments in experiment_list:\n",
    "        # Start the title with the experiment number\n",
    "        title = \"\"\n",
    "\n",
    "        # Include model in title\n",
    "        if \"resnet\" in experiments[0].lower():\n",
    "            title += \"Model: ResNet\"\n",
    "        elif \"vit\" in experiments[0].lower():\n",
    "            title += \"Model: ViT\"\n",
    "\n",
    "        # Save the individual results for the plots\n",
    "        results_values = {}\n",
    "\n",
    "        # Loop through the individual experiments\n",
    "        for experiment in experiments:\n",
    "            df = pd.read_csv(base_directory + \"image_classification/\" + experiment)\n",
    "\n",
    "            # Get the 100 results\n",
    "            results = df[image_results_column].values\n",
    "            # Calculate the summary statistics\n",
    "            distribution_mean = metrics.safe_round(metrics.mean(results), round_digits)\n",
    "            distribution_range = metrics.safe_round(metrics.range(results), round_digits)\n",
    "            distribution_std = metrics.safe_round(metrics.standard_deviation(results), round_digits)     \n",
    "            shapiro_p = metrics.safe_round(metrics.shapiro_test(results)[1], round_digits)\n",
    "            skewness = metrics.safe_round(metrics.skewness(results), round_digits)\n",
    "            lower_fence_outliers = metrics.lower_fence_outliers(results)\n",
    "            upper_fence_outliers = metrics.upper_fence_outliers(results)\n",
    "\n",
    "            # Get the model and dataset from the experiment name\n",
    "            dataset = experiment.split(\"-\")[1]\n",
    "            model = experiment.split(\"-\")[0]\n",
    "\n",
    "            # Get the model parameters\n",
    "            parameters = metrics.parameters(model)\n",
    "\n",
    "            # Add the dataset to the title if it is not already there\n",
    "            if \"CIFAR\" not in title and \"Oxford\" not in title and \"UC Merced\" not in title:\n",
    "                if dataset == \"cifar10\":\n",
    "                    title = title + \" Dataset: CIFAR-10\"\n",
    "                elif dataset == \"cifar100\":\n",
    "                    title = title + \" Dataset: CIFAR-100\"\n",
    "                elif dataset == \"oxford_flowers102\":\n",
    "                    title = title + \" Dataset: Oxford Flowers\"\n",
    "                elif dataset == \"uc_merced\":\n",
    "                    title = title + \"Dataset: UC Merced\"                \n",
    "\n",
    "            # Add whether the model is pretrained or not for the ViT 16 models\n",
    "            if \"vit\" in model.lower() and \"16\" in model.lower():\n",
    "                if \"pretrained\" in experiment:\n",
    "                    model += \" (Pretrained)\"\n",
    "                    if \"pretrained\" not in title.lower():\n",
    "                        title += \" (Pretrained)\"\n",
    "                else:\n",
    "                    model += \" (Random)\"\n",
    "                    if \"random\" not in title.lower():\n",
    "                        title += \" (Random)\"\n",
    "\n",
    "            # Convert the results to percentages\n",
    "            results = results * 100\n",
    "            # Save the results for the plot\n",
    "            results_values[model] = results\n",
    "\n",
    "            # Save the summary statistics\n",
    "            summary_statistics.append([dataset, model, parameters, distribution_mean, distribution_range, distribution_std, skewness, shapiro_p, lower_fence_outliers, upper_fence_outliers])\n",
    "\n",
    "        # Save the results for the experiment\n",
    "        experiment_data[title] = results_values\n",
    "\n",
    "    # Plot the results for the experiment as a KDE histogram\n",
    "    save_kde(experiment_data, \"Top-1 Accuracy (%)\", \"plots/results/ic/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics_df = pd.DataFrame(summary_statistics, columns=[\"dataset\", \"model\", \"parameters\", \"mean\", \"range\", \"std\", \"skewness\", \"shapiro_p\", \"lower_outliers\", \"upper_outliers\"])\n",
    "summary_statistics_df.to_csv(\"image_summary_statistics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_results = [\n",
    "    [\n",
    "        [\"Autoformer_ETTh1_96_96_0_100.csv\", \"iTransformer_ETTh1_96_96_0_100.csv\", \"NLinear_ETTh1_96_96_0_100.csv\", \"TSMixer_ETTh1_96_96_0_100.csv\"],\n",
    "        [\"Autoformer_ETTh1_96_192_0_100.csv\", \"iTransformer_ETTh1_96_192_0_100.csv\", \"NLinear_ETTh1_96_192_0_100.csv\", \"TSMixer_ETTh1_96_192_0_100.csv\"],\n",
    "        [\"Autoformer_ETTh1_96_336_0_100.csv\", \"iTransformer_ETTh1_96_336_0_100.csv\", \"NLinear_ETTh1_96_336_0_100.csv\", \"TSMixer_ETTh1_96_336_0_100.csv\"],\n",
    "        [\"Autoformer_ETTh1_96_720_0_100.csv\", \"iTransformer_ETTh1_96_720_0_100.csv\", \"NLinear_ETTh1_96_720_0_100.csv\", \"TSMixer_ETTh1_96_720_0_100.csv\"],\n",
    "    ],\n",
    "    [\n",
    "        [\"Autoformer_ETTh2_96_96_0_100.csv\", \"iTransformer_ETTh2_96_96_0_100.csv\", \"NLinear_ETTh2_96_96_0_100.csv\", \"TSMixer_ETTh2_96_96_0_100.csv\"],\n",
    "        [\"Autoformer_ETTh2_96_192_0_100.csv\", \"iTransformer_ETTh2_96_192_0_100.csv\", \"NLinear_ETTh2_96_192_0_100.csv\", \"TSMixer_ETTh2_96_192_0_100.csv\"],\n",
    "        [\"Autoformer_ETTh2_96_336_0_100.csv\", \"iTransformer_ETTh2_96_336_0_100.csv\", \"NLinear_ETTh2_96_336_0_100.csv\", \"TSMixer_ETTh2_96_336_0_100.csv\"],\n",
    "        [\"Autoformer_ETTh2_96_720_0_100.csv\", \"iTransformer_ETTh2_96_720_0_100.csv\", \"NLinear_ETTh2_96_720_0_100.csv\", \"TSMixer_ETTh2_96_720_0_100.csv\"],\n",
    "    ],\n",
    "    [\n",
    "        [\"Autoformer_ETTm1_96_96_0_100.csv\", \"iTransformer_ETTm1_96_96_0_100.csv\", \"NLinear_ETTm1_96_96_0_100.csv\", \"TSMixer_ETTm1_96_96_0_100.csv\"],\n",
    "        [\"Autoformer_ETTm1_96_192_0_100.csv\", \"iTransformer_ETTm1_96_192_0_100.csv\", \"NLinear_ETTm1_96_192_0_100.csv\", \"TSMixer_ETTm1_96_192_0_100.csv\"],\n",
    "        [\"Autoformer_ETTm1_96_336_0_100.csv\", \"iTransformer_ETTm1_96_336_0_100.csv\", \"NLinear_ETTm1_96_336_0_100.csv\", \"TSMixer_ETTm1_96_336_0_100.csv\"],\n",
    "        [\"Autoformer_ETTm1_96_720_0_100.csv\", \"iTransformer_ETTm1_96_720_0_100.csv\", \"NLinear_ETTm1_96_720_0_100.csv\", \"TSMixer_ETTm1_96_720_0_100.csv\"],\n",
    "    ],\n",
    "    [\n",
    "        [\"Autoformer_ETTm2_96_96_0_100.csv\", \"iTransformer_ETTm2_96_96_0_100.csv\", \"NLinear_ETTm2_96_96_0_100.csv\", \"TSMixer_ETTm2_96_96_0_100.csv\"],\n",
    "        [\"Autoformer_ETTm2_96_192_0_100.csv\", \"iTransformer_ETTm2_96_192_0_100.csv\", \"NLinear_ETTm2_96_192_0_100.csv\", \"TSMixer_ETTm2_96_192_0_100.csv\"],\n",
    "        [\"Autoformer_ETTm2_96_336_0_100.csv\", \"iTransformer_ETTm2_96_336_0_100.csv\", \"NLinear_ETTm2_96_336_0_100.csv\", \"TSMixer_ETTm2_96_336_0_100.csv\"],\n",
    "        [\"Autoformer_ETTm2_96_720_0_100.csv\", \"iTransformer_ETTm2_96_720_0_100.csv\", \"NLinear_ETTm2_96_720_0_100.csv\", \"TSMixer_ETTm2_96_720_0_100.csv\"],\n",
    "    ],\n",
    "    [\n",
    "        [\"Autoformer_traffic_96_96_0_100.csv\", \"iTransformer_traffic_96_96_0_100.csv\", \"NLinear_traffic_96_96_0_100.csv\", \"TSMixer_traffic_96_96_0_100.csv\"],\n",
    "        [\"Autoformer_traffic_96_192_0_100.csv\", \"iTransformer_traffic_96_192_0_100.csv\", \"NLinear_traffic_96_192_0_100.csv\", \"TSMixer_traffic_96_192_0_100.csv\"],\n",
    "        [\"Autoformer_traffic_96_336_0_100.csv\", \"NLinear_traffic_96_336_0_100.csv\", \"TSMixer_traffic_96_336_0_100.csv\"],\n",
    "        [\"Autoformer_traffic_96_720_0_100.csv\", \"NLinear_traffic_96_720_0_100.csv\", \"TSMixer_traffic_96_720_0_100.csv\"],\n",
    "    ],\n",
    "    [\n",
    "        [\"Autoformer_weather_96_96_0_100.csv\", \"iTransformer_weather_96_96_0_100.csv\", \"NLinear_weather_96_96_0_100.csv\", \"TSMixer_weather_96_96_0_100.csv\"],\n",
    "        [\"Autoformer_weather_96_192_0_100.csv\", \"iTransformer_weather_96_192_0_100.csv\", \"NLinear_weather_96_192_0_100.csv\", \"TSMixer_weather_96_192_0_100.csv\"],\n",
    "        [\"Autoformer_weather_96_336_0_100.csv\", \"iTransformer_weather_96_336_0_100.csv\", \"NLinear_weather_96_336_0_100.csv\", \"TSMixer_weather_96_336_0_100.csv\"],\n",
    "        [\"Autoformer_weather_96_720_0_100.csv\", \"iTransformer_weather_96_720_0_100.csv\", \"NLinear_weather_96_720_0_100.csv\", \"TSMixer_weather_96_720_0_100.csv\"],\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary statistics so they can be saved to a CSV file\n",
    "summary_statistics = []\n",
    "\n",
    "for idx, experiment_list in enumerate(time_series_results):\n",
    "\n",
    "    experiment_data = {}\n",
    "\n",
    "    for experiments in experiment_list:\n",
    "        # Start the title with the experiment number\n",
    "        title = \"\"\n",
    "        horizon = experiments[1].split(\"_\")[3]\n",
    "\n",
    "        # Save the individual results for the plots\n",
    "        results_values = {}\n",
    "\n",
    "        # Loop through the individual experiments\n",
    "        for experiment in experiments:\n",
    "            df = pd.read_csv(base_directory + \"time_series/\" + experiment)\n",
    "\n",
    "            # Get the 100 results\n",
    "            results = df[time_results_column].values\n",
    "            # Calculate the summary statistics\n",
    "            distribution_mean = metrics.safe_round(metrics.mean(results), round_digits)\n",
    "            distribution_range = metrics.safe_round(metrics.range(results), round_digits)\n",
    "            distribution_std = metrics.safe_round(metrics.standard_deviation(results), round_digits)     \n",
    "            shapiro_p = metrics.safe_round(metrics.shapiro_test(results)[1], round_digits)\n",
    "            skewness = metrics.safe_round(metrics.skewness(results), round_digits)\n",
    "            lower_fence_outliers = metrics.lower_fence_outliers(results)\n",
    "            upper_fence_outliers = metrics.upper_fence_outliers(results) \n",
    "\n",
    "            # Get the model and dataset from the experiment name\n",
    "            dataset = experiment.split(\"_\")[1]\n",
    "            model = experiment.split(\"_\")[0]\n",
    "\n",
    "            # Get the model parameters\n",
    "            parameters = metrics.parameters(model, dataset, horizon)\n",
    "\n",
    "            # Add the dataset to the title if it is not already there\n",
    "            if dataset not in title:\n",
    "                title = \"Dataset: \" + dataset + \" Horizon: \" + horizon\n",
    "\n",
    "            # Save the results for the plot\n",
    "            results_values[model] = results\n",
    "\n",
    "            # Save the summary statistics\n",
    "            summary_statistics.append([dataset, model, horizon, parameters, distribution_mean, distribution_range, distribution_std, skewness, shapiro_p, lower_fence_outliers, upper_fence_outliers])\n",
    "\n",
    "        # Save the results for the experiment\n",
    "        experiment_data[title] = results_values\n",
    "\n",
    "    # Plot the results for the experiment as a KDE histogram\n",
    "    save_kde(experiment_data, \"Mean Absolute Error\", \"plots/results/ts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics_df = pd.DataFrame(summary_statistics, columns=[\"dataset\", \"model\", \"horizon\", \"parameters\", \"mean\", \"range\", \"std\", \"skewness\", \"shapiro_p\", \"lower_outliers\", \"upper_outliers\"])\n",
    "summary_statistics_df.to_csv(\"time_series_summary_statistics_mae.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
