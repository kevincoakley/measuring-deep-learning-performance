{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e49dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import json\n",
    "import metrics\n",
    "\n",
    "round_precision = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ec031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation(csv_files, column_name):\n",
    "    # Store performance and robustness metrics\n",
    "    metric_results = []\n",
    "\n",
    "    # Loop through each CSV and calculate metrics\n",
    "    for path in csv_files:\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        if column_name in df.columns:\n",
    "            # Top-1 Accuracy\n",
    "            if column_name == \"test_accuracy\":\n",
    "                plot_file_path = \"plots/rq4/image.pdf\"\n",
    "                file = os.path.basename(path)\n",
    "                model = file.split(\"-\")[0]\n",
    "                dataset = file.split(\"-\")[1]\n",
    "\n",
    "                if dataset == \"cifar10\":\n",
    "                    dataset = \"CIFAR-10\"\n",
    "                elif dataset == \"cifar100\":\n",
    "                    dataset = \"CIFAR-100\"\n",
    "                elif dataset == \"oxford_flowers102\":\n",
    "                    dataset = \"Oxford Flowers\"\n",
    "                elif dataset == \"uc_merced\":\n",
    "                    dataset = \"UC Merced\"\n",
    "\n",
    "                # Check if the file is pretrained or randomly initialized\n",
    "                if \"pretrained\" in file:\n",
    "                    dataset = dataset + \" (P)\"\n",
    "                else:\n",
    "                    dataset = dataset + \" (R)\"\n",
    "                \n",
    "                metric_results.append({\n",
    "                    \"file\": file,\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"mean\": (1 - metrics.mean(df[column_name].to_list())) * 100,\n",
    "                    \"range\": metrics.range(df[column_name].to_list()) * 100,\n",
    "                })\n",
    "\n",
    "                title = \"Correlation Plot for Mean Top-1 Error Rate\\nand Range for Image Classification\"\n",
    "                x_label = \"Mean Top-1 Error Percentage\"\n",
    "            # MAE\n",
    "            elif column_name == \"mae\":\n",
    "                plot_file_path = \"plots/rq4/time_series.pdf\"\n",
    "                file = os.path.basename(path)\n",
    "                model = file.split(\"_\")[0]\n",
    "                dataset = file.split(\"_\")[1]\n",
    "\n",
    "                metric_results.append({\n",
    "                    \"file\": file,\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"mean\": metrics.mean(df[column_name].to_list()),\n",
    "                    \"range\": metrics.range(df[column_name].to_list()),\n",
    "                })\n",
    "\n",
    "                title = \"Correlation Plot for Mean MAE\\nand Range for Time Series Forecasting\"\n",
    "                x_label = \"Mean MAE\"\n",
    "\n",
    "\n",
    "    # Create DataFrame\n",
    "    metrics_df = pd.DataFrame(metric_results)\n",
    "\n",
    "    # Compute Pearson correlation and p-value\n",
    "    r_value, p_value = metrics.correlation(metrics_df[\"mean\"], metrics_df[\"range\"])\n",
    "\n",
    "    r_value = metrics.safe_round(r_value, round_precision)\n",
    "    p_value = metrics.safe_round(p_value, round_precision)\n",
    "\n",
    "    # Display results\n",
    "    print(\"Correlation between performance (mean) and robustness (range):\")\n",
    "    print(\"Pearson r =\", r_value)\n",
    "    print(\"p-value   =\", p_value)\n",
    "\n",
    "    # Show metrics for transparency\n",
    "    #print(\"\\nPer-file performance and robustness metrics:\")\n",
    "    #print(metrics_df)\n",
    "\n",
    "   \n",
    "    # Create DataFrame\n",
    "    #metrics_df = pd.DataFrame(metric_results)\n",
    "\n",
    "    # Set up color palette and marker style\n",
    "    model_markers = {model: marker for model, marker in zip(metrics_df[\"model\"].unique(), ['o', 's', '^', 'D', 'P', 'X', 'v', '<', '>', 'h', 'H', '*', '+', 'x'])}\n",
    "    dataset_palette = sns.color_palette(\"bright\", len(metrics_df[\"dataset\"].unique()))\n",
    "    dataset_colors = dict(zip(metrics_df[\"dataset\"].unique(), dataset_palette))\n",
    "\n",
    "    # Plot correlation\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for _, row in metrics_df.iterrows():\n",
    "        plt.scatter(\n",
    "            row[\"mean\"], row[\"range\"],\n",
    "            color=dataset_colors[row[\"dataset\"]],\n",
    "            marker=model_markers[row[\"model\"]],\n",
    "            label=f'{row[\"model\"]}/{row[\"dataset\"]}',\n",
    "            s=200,\n",
    "        )\n",
    "\n",
    "    \n",
    "    model_legend = [\n",
    "        Line2D([0], [0], marker=marker, color='black', linestyle='', label=model) \n",
    "        for model, marker in sorted(model_markers.items())\n",
    "    ]\n",
    "\n",
    "    dataset_legend = [\n",
    "        Line2D([0], [0], marker='o', color=color, linestyle='', label=dataset) \n",
    "        for dataset, color in sorted(dataset_colors.items())\n",
    "    ]\n",
    "    \n",
    "    plt.legend(handles=model_legend + dataset_legend, title='Model / Dataset', fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(x_label, fontsize=13)\n",
    "    plt.ylabel(\"Range\", fontsize=13)\n",
    "    plt.tick_params(labelsize=13)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    # Save the plot\n",
    "    \n",
    "    plt.savefig(plot_file_path, dpi=600, pad_inches=0.1, bbox_inches='tight')  # Save the plot with proper bounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f6d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your data directory here\n",
    "data_folder = \"../results/image_classification/\"\n",
    "\n",
    "# Automatically find all CSV files in the directory that contain 'PyTorch' in the filename\n",
    "csv_files = [f for f in glob.glob(os.path.join(data_folder, \"*.csv\")) if \"PyTorch\" in os.path.basename(f)]\n",
    "\n",
    "calculate_correlation(csv_files, \"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e59f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your data directory here\n",
    "data_folder = \"../results/time_series/\"\n",
    "\n",
    "# Automatically find all CSV files in the directory that contain '96_192' in the filename\n",
    "csv_files = [f for f in glob.glob(os.path.join(data_folder, \"*.csv\"))]\n",
    "\n",
    "calculate_correlation(csv_files, \"mae\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
